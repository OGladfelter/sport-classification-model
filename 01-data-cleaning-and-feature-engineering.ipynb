{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c665d76",
   "metadata": {},
   "source": [
    "# Clean and prep data for modeling\n",
    "## Author: Oliver Gladfelter\n",
    "## Feb 20, 2026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "56098dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# GPX stuff\n",
    "import polyline\n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2334cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_of_day(hour):\n",
    "    \"\"\" categorize hour --> day part\"\"\"\n",
    "    if 5 <= hour < 12:\n",
    "        return 'morning'\n",
    "    elif 12 <= hour < 17:\n",
    "        return 'afternoon'\n",
    "    elif 17 <= hour < 21:\n",
    "        return 'evening'\n",
    "    else:\n",
    "        return 'night'\n",
    "\n",
    "# a new mapping to group the sport types in a new column\n",
    "sport_types_dict = {\n",
    "    'Ride': 'Ride',\n",
    "    'Walk': 'Walk',\n",
    "    'Run': 'Run',\n",
    "    'Hike': 'Hike',\n",
    "    'InlineSkate': 'Workout',\n",
    "    'Workout': 'Workout',\n",
    "    'Rowing': 'Workout',\n",
    "    'AlpineSki': 'Workout',\n",
    "    'Snowboard': 'Workout',\n",
    "    'Swim': 'Workout',\n",
    "    'Crossfit': 'Workout',\n",
    "    'RollerSki': 'Workout',\n",
    "    'EBikeRide': 'Ride',\n",
    "    'VirtualRide': 'Ride',\n",
    "    'Snowshoe': 'Walk',\n",
    "    'WeightTraining': 'Workout',\n",
    "    'BackcountrySki': 'Workout',\n",
    "    'Kayaking': 'Workout',\n",
    "    'NordicSki': 'Workout',\n",
    "    'IceSkate': 'Workout',\n",
    "    'Yoga': 'Workout',\n",
    "    'MountainBikeRide': 'Ride',\n",
    "    'StandUpPaddling': 'Workout',\n",
    "    'Windsurf': 'Workout',\n",
    "    'RockClimbing': 'Workout',\n",
    "    'Elliptical': 'Workout',\n",
    "    'Surfing': 'Workout',\n",
    "    'Canoeing': 'Workout',\n",
    "    'Velomobile': 'Workout',\n",
    "    'StairStepper': 'Workout',\n",
    "    'Sail': 'Workout',\n",
    "    'TrailRun': 'Run',\n",
    "    'VirtualRun': 'Run',\n",
    "    'EMountainBikeRide': 'Ride',\n",
    "    'GravelRide': 'Ride', \n",
    "    'Skateboard': 'Workout', \n",
    "    'Soccer': 'Workout', \n",
    "    'TableTennis': 'Workout', \n",
    "    'Pilates': 'Workout',\n",
    "    'HighIntensityIntervalTraining': 'Workout', \n",
    "    'VirtualRow': 'Workout', \n",
    "    'Golf': 'Workout', \n",
    "    'Tennis': 'Workout',\n",
    "    'Kitesurf': 'Workout', \n",
    "    'Pickleball': 'Workout', \n",
    "    'Squash': 'Workout', \n",
    "    'Badminton': 'Workout', \n",
    "    'Racquetball': 'Workout',\n",
    "    'Wheelchair': 'Workout'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20575fec",
   "metadata": {},
   "source": [
    "# Load & wrangle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "31bdc3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399646\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/activities_export.tsv\", sep=\"\\t\", encoding=\"latin-1\")\n",
    "\n",
    "# filter out activities set to view=\"only_me\"\n",
    "df = df[df['private'] == 0]\n",
    "\n",
    "# drop workouts that have GPS data but the total distance is less than 200 meters\n",
    "df = df[~(df['map_summary_polyline'].notnull() & (df['distance'] < 200))]\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0212e615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the polyline code (need to ditch the double escape)\n",
    "df['map_summary_polyline'] = df['map_summary_polyline'].str.replace('\\\\\\\\', '\\\\', regex=False)\n",
    "\n",
    "# convert start_date_local from str to datetime object\n",
    "df['start_date'] = pd.to_datetime(df['start_date_local'])\n",
    "\n",
    "# start_date includes year, month, day, and timestamp --> ex: 2011-04-06 15:20:10\n",
    "# get hour from start_date, then compute day_part column\n",
    "df['hour'] = df['start_date'].dt.hour\n",
    "df['day_part'] = df['hour'].apply(get_time_of_day)\n",
    "\n",
    "# extract month (which later may be useful in conjunction with is is_northern_hemisphere --> Winter, Summer, etc)\n",
    "df['month'] = df['start_date'].dt.month\n",
    "\n",
    "# also create is_weekend flag\n",
    "df['dayofweek'] = df['start_date'].dt.dayofweek\n",
    "df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)\n",
    "\n",
    "# people usually talk distance in terms of miles or kilometers, not meters\n",
    "df['miles'] = df['distance'] / 1609\n",
    "df['kilometers'] = df['distance'] / 1000\n",
    "\n",
    "# avg speed of the workout\n",
    "df['speed_mph'] = df['miles'] / (df['elapsed_time'] / 3600)\n",
    "# speed_mph will be inf if elapsed_time == 0, will be NaN if miles == 0 \n",
    "# but there are valid reasons why these values might be 0, so let's replace inf and NaN values with 0s\n",
    "df['speed_mph'] = df['speed_mph'].replace([np.inf, -np.inf], np.nan)\n",
    "df['speed_mph'] = df['speed_mph'].fillna(0) # stationary activities\n",
    "\n",
    "# create boolean feature to show if activity was in the northern hemisphere\n",
    "df['is_northern_hemisphere'] = (df['start_lat'] > 0).astype(int) # 1 = is northern hemisphere, 0 = southern\n",
    "\n",
    "# we have total_elevation_gain, which is in meters. But this isn't super helpful on its own:\n",
    "# I suspect gain-over-distance is more predictive\n",
    "df['meters_per_km'] = df['total_elevation_gain'] / df['kilometers']\n",
    "df['feet_per_mile'] = (df['total_elevation_gain'] * 3.28084) / df['miles'] # for the Americans lmao\n",
    "\n",
    "# having the time metrics available in minutes (as well as seconds) will be helpful\n",
    "df['moving_minutes'] = df['moving_time'] / 60\n",
    "df['elapsed_minutes'] = df['elapsed_time'] / 60\n",
    "\n",
    "# Make a moving:elapsed time percentage (was there constant movement or was there lot of total downtime?)\n",
    "df['moving_time_per'] = df['moving_time'] / df['elapsed_time']\n",
    "\n",
    "# Make a boolean for gear_id : is gear added or not (depends on user input)\n",
    "df['has_gear'] = df['gear_id'].notnull()\n",
    "\n",
    "# create a grouped sport type column using dict defined above\n",
    "df['sport_type_grouped'] = df['sport_type'].map(sport_types_dict)\n",
    "\n",
    "# 'activity_title' is a much more descriptive column name than 'name', 'id' instead of 'strava_activity_id' is for convenience\n",
    "df = df.rename(columns={'name': 'activity_title', 'strava_activity_id':'id'})\n",
    "\n",
    "# mask the IDs to hide PII\n",
    "df['id'] = df['id'].map({id_val: i for i, id_val in enumerate(df['id'].unique(), 1)})\n",
    "df['user_id'] = df['user_id'].map({uid: i for i, uid in enumerate(df['user_id'].unique(), 1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c359b1",
   "metadata": {},
   "source": [
    "## GPX Features\n",
    "\n",
    "Workouts recorded with a GPS device represent the GPX data in map polylines codes. These coded strings can be decoded into arrays of latitude and longitude coordinates. \n",
    "\n",
    "See https://developers.google.com/maps/documentation/routes/polylinedecoder. \n",
    "\n",
    "We will extract the following information from the GPX data:\n",
    "- Number of total turns\n",
    "- Avg turns per mile\n",
    "- Wobble of trace (trace follows straight lines vs curving, winding routes / how rounded are some paths vs how rigid are the lines?)\n",
    "- Sprawl: derived from bounding box diag distance (straight-line distance in miles between the two corners of the bounding box around a trace - proxy for compact vs sprawl)\n",
    "\n",
    "\n",
    "Note many of the activities are manual, indoor activities, stationary activities, etc and therefore are missing `map_summary_polyline` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "391da183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_polyline(poly):\n",
    "    \"\"\"\n",
    "    Returns array of lat,lng coordinates for a gps trace (map_summary_polyline, in this case)\n",
    "    Skips null or empty string values (for indoor activities or workouts with no GPS)\n",
    "    \"\"\"\n",
    "    if pd.isnull(poly) or poly == \"\":\n",
    "        return None\n",
    "    try:\n",
    "        coords = polyline.decode(poly)[::10]\n",
    "        return coords if len(coords) >= 2 else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def bearing(p1, p2):\n",
    "    \"\"\"\n",
    "    returns degrees change in direction between two lat,lng points\n",
    "    params: two points ([lat,lng])\n",
    "    convert degrees to radians, then compute the compass bearing between two coordinates\n",
    "    uses spherical geometry (which requires converting degrees to radians)\n",
    "    \"\"\"\n",
    "    lat1, lon1 = np.radians(p1)\n",
    "    lat2, lon2 = np.radians(p2)\n",
    "    return np.degrees(np.arctan2(np.sin(lon2-lon1)*np.cos(lat2), \n",
    "                                  np.cos(lat1)*np.sin(lat2) - np.sin(lat1)*np.cos(lat2)*np.cos(lon2-lon1)))\n",
    "\n",
    "def calc_turn_metrics(coords, total_miles):\n",
    "    \"\"\"\n",
    "    returns:\n",
    "        - number of turns in a GPS trace, \n",
    "        - number of turns per mile\n",
    "        - wobble\n",
    "    param: an entire array of lat,lng coordinates\n",
    "    uses 45 as the threshold for a 'turn' -- i.e. trace must change direction over 45 degrees for the \n",
    "    direction change to count as a turn\n",
    "    uses bearing() to get degrees direction change, sums up all instances > turn_threshold\n",
    "    \n",
    "    So both num_turns and wobble considers changes in directions (measured by in bearings by bearing())\n",
    "    But num_turns only counts changes in direction above a set threshold (45 degrees) as a turn\n",
    "    \n",
    "    wobble considers bearing changes under the threshold and sums up the magnitude of the bearings\n",
    "    So if someone runs a square, and it's all straight lines, even with the 3 rigid turns, the route is not thought of as 'wobbly'\n",
    "    wobble sums up minor bearings (< threshold) to account for minor and larger changes in direction\n",
    "    We would likely see highest values on trail runs - following a straight but curvy path, for example,\n",
    "    rather than in a city with straight sidewalks\n",
    "    \"\"\"\n",
    "    turn_threshold = 45 # angle threshold for what counts as a \"turn\" (measured in degrees)\n",
    "    bearings = [bearing(coords[i], coords[i+1]) for i in range(len(coords)-1)]\n",
    "    changes = [abs(bearings[i+1] - bearings[i]) for i in range(len(bearings)-1)]\n",
    "    changes = [c if c <= 180 else 360 - c for c in changes] # handle wrap-around (going from 350 -> 10 should be thought of as 20 degrees, not 340)\n",
    "    \n",
    "    # final metrics\n",
    "    num_turns = sum(c > turn_threshold for c in changes) # total number of turns\n",
    "    wobble = sum(c for c in changes if c <= turn_threshold) / total_miles if total_miles > 0 else None\n",
    "    turns_per_mile = num_turns / total_miles if total_miles > 0 else None\n",
    "    \n",
    "    return num_turns, turns_per_mile, wobble\n",
    "\n",
    "def calc_bbox_diagonal(coords):\n",
    "    \"\"\"\n",
    "    Return distance (in miles) between the most northwest and the most southeast lat,lng coordinates\n",
    "    This is a proxy for a compact route (loops in a park) vs a sprawling route (big rectangle around a neighborhood)\n",
    "    \n",
    "    param: the array of lat,lng coords\n",
    "    \"\"\"\n",
    "    lats = [c[0] for c in coords]\n",
    "    lngs = [c[1] for c in coords]\n",
    "    corner1 = (min(lats), min(lngs))\n",
    "    corner2 = (max(lats), max(lngs))\n",
    "    return geodesic(corner1, corner2).miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b89bfea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "    coords = decode_polyline(row['map_summary_polyline']) # returns None if there is no polyline code\n",
    "    if coords: # skip when null\n",
    "        num_turns, turns_per_mile, wobble = calc_turn_metrics(coords, row['miles'])\n",
    "        df.at[i, 'num_turns'] = num_turns\n",
    "        df.at[i, 'turns_per_mile'] = turns_per_mile\n",
    "        df.at[i, 'wobble'] = wobble\n",
    "        df.at[i, 'sprawl'] = calc_bbox_diagonal(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72553b8a",
   "metadata": {},
   "source": [
    "# Export for use in next notebook: `02-eda.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a4ac6d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns to move forward with\n",
    "features = [\n",
    "    'id', \n",
    "    'user_id', \n",
    "    'sport_type', \n",
    "    'sport_type_grouped', \n",
    "    'speed_mph',\n",
    "    'distance', \n",
    "    'miles', \n",
    "    'kilometers',\n",
    "    'moving_time', \n",
    "    'elapsed_time', \n",
    "    'moving_minutes', \n",
    "    'elapsed_minutes', \n",
    "    'moving_time_per',\n",
    "    'total_elevation_gain',\n",
    "    'meters_per_km', \n",
    "    'feet_per_mile',\n",
    "    'commute', \n",
    "    'manual', \n",
    "    'has_gear',\n",
    "    'suffer_score', \n",
    "    'kudos_count', \n",
    "    'device_name', \n",
    "    'start_date', \n",
    "    'hour', \n",
    "    'day_part', \n",
    "    'month', \n",
    "    'dayofweek', \n",
    "    'is_weekend', \n",
    "    'is_northern_hemisphere',\n",
    "    'num_turns',\n",
    "    'turns_per_mile',\n",
    "    'wobble',\n",
    "    'sprawl'\n",
    "]\n",
    "\n",
    "df = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c539cbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has 398442 rows and 32 columns\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data has {len(df)} rows and {len(df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e7464ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/processed_activities.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bf08a1",
   "metadata": {},
   "source": [
    "# Also export a smaller sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76473010",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"processed_activities.csv\")\n",
    "df = df.sample(10000).reset_index(drop=True)\n",
    "df.to_csv(\"sample_workout_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
